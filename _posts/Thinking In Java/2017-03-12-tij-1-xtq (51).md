---
layout: 	post
title: 		"Java编程思想笔记<二十一>"
subtitle:	"Concurrency"
date: 		2017-3-12 11:40:00
author: 	"玄天强"
header-img:	"img/mn-bg-xtq.jpg"
catalog: true
tags:
    - Thinking in Java
---

*	However, becoming adept at concurrent programming theory and techniques is a step up from everything you’ve learned so far in this book, and is an intermediate to advanced topic.
*	熟悉并发编程理论与技术是学习本书以来的一个进步，也是向更高级话题的一个中介。
*	In practice, however, it’s much easier to write concurrent programs that only appear to work, but given the right conditions, will fail. 
*	但在实际中，更可能写出看起来有用的并发程序，但在给定的正确条件下却会失败。
*	In fact, you may not be able to write test code that will generate failure conditions for your concurrent program.
*	事实上，你可能难以写出对你的并发程序产生失败条件的测试代码。
*	With concurrency, you’re on your own, and only by being both suspicious and aggressive can you write multithreaded code in Java that will be reliable. 
*	对于并发，你只能靠自己，而且你只有积极怀疑才可以写出Java中可靠的多线程代码。
*	You never start a thread yourself doesn’t mean you’ll be able to avoid writing threaded code.
*	你从来没启动过一个线程并不是说你可以避免写线程代码。
*	Web servers often contain multiple processors, and concurrency is an ideal way to utilize these processors.
*	Web服务器通常包含多个处理器，并发是一种理想的利用这些处理器的方式。
*	Basically, knowing about concurrency makes you aware that apparently correct programs can exhibit incorrect behavior.
*	基本上，知道并发使你意识到表面上正确的程序可以造成错误的行为。

##	The many faces of concurrency
*	You’re forced to understand all issues and special cases in order to use concurrency effectively.
*	要高效使用并发，你得理解所有问题及特殊情况。

###	Faster execution
*	If you want a program to run faster, break it into pieces and run each piece on a separate processor.
*	如果你想让一个程序跑得更快些，就将它们揉碎然后在单独的处理器上跑每块。
*	If you have a multiprocessor machine, multiple tasks can be distributed across those processors, which can dramatically improve throughput.
*	如果你有一个多处理器的机子，多个任务就可以分布在这些处理器上，这样可以大幅地提高吞吐量。
*	However, concurrency can often improve the performance of programs running on a single processor.
*	但是并发通常可以提高跑在一个单独处理器上的程序的性能。
*	If the program is written using concurrency, however, the other tasks in the program can continue to execute when one task is blocked, so the program continues to move forward.
*	如果程序是用并发写的，程序中的其他任务就可以在一个任务阻塞时继续执行，因此程序可以继续向下执行。
*	It makes no sense to use concurrency on a single-processor machine unless one of the tasks might block.
*	在单处理器除非其中一个任务可能阻塞，否则用并发没啥卵用。
*	One of the most compelling reasons for using concurrency is to produce a responsive user interface.
*	用并发的主要原因之一是产生响应式的用户接口。
*	By creating a separate thread of execution to respond to user input, even though this thread will be blocked most of the time, the program guarantees a certain level of responsiveness.
*	通过创建一个单独的执行线程来响应用户输入，尽管这个线程大多数时候会阻塞，程序保证了一定程度的响应。
*	One very straightforward way to implement concurrency is at the operating system level, using *processes*.
*	一种非常直白的实现并发的方式是在操作系统层面上用进程。
*	A multitasking operating system can run more than one process (program) at a time by periodically switching the CPU from one process to another, while making it look as if each process is chugging along on its own.
*	一个多任务的操作系统通过周期性的从一个进程向另一个转换CPU可以同时跑多个进程,这就使得看起来每个进程都是自己的。
*	The fundamental difficulty in writing multithreaded programs is coordinating the use of these resources between different thread-driven tasks, so that they cannot be accessed by more than one task at a time.
*	写并发程序的基本困难是在不同线程驱动任务间协调这些资源，以使它们不能被多个任务同时访问。
*	This is an ideal example of concurrency. Each task executes as a process in its own address space, so there’s no possibility of interference between tasks.
*	这是并发的一个理想示例，每个任务作为一个进程在其自个的地址空间执行，因此任务间不会有冲突的可能。
*	There are generally quantity and overhead limitations to processes that prevent their applicability across the concurrency spectrum.
*	通常对进程有数量和过载的限制来保护他们在并发中的适应性。
*	Instead of forking external processes in a multitasking operating system, threading creates tasks *within* the single process represented by the executing program.  
*	线程在一个由执行程序表示的进程中创建任务，代替了在一个多任务操作系统中对外部进程进行分支。

###	Improving code design
*	Multithreaded systems often have a relatively small size limit on the number of threads available, sometimes on the order of tens or hundreds.  
*	多线程系统通常会在可用线程的数目上有一个相对小的限制，有时会是几十或几百的阶数。
*	In Java, you can generally assume that you will not have enough threads available to provide one for each element in a large simulation.
*	Java中，你通常在一个大的模拟中可以假设你没有足够的可用线程来为每个元素提供一个。
*	Java’s threading is preemptive, which means that a scheduling mechanism provides time slices for each thread, periodically interrupting a thread and context switching to another thread so that each one is given a reasonable amount of time to drive its task.
*	Java的线程是抢占式的，这意味着一个调度机制给每个线程提供时间片，周期性地中断一个线程进行上下文切换，由此给每个线程合理的时间来做自己的任务。
*	In general, threads enable you to create a more loosely coupled design; otherwise, parts of your code would be forced to pay explicit attention to tasks that would normally be handled by threads.
*	一般来说，线程使得你可以创建一个更松耦合的设计，否则，你的部分代码将被强制显式处理正常情况下会被线程处理的任务。
	  
##	Basic threading
*	A thread is a single sequential flow of control within a process.
*	一个线程是进程内一个单独的控制流序列
*	One of the great things about threading is that you are abstracted away from this layer, so your code does not need to know whether it is running on a single CPU or many.
*	线程的一大好处是你从这层抽象出来了，因此你的代码无需知道它是跑在一个单CPU还是多个上。 

###	Defining tasks
*	A task’s **run( )** method usually has some kind of loop that continues until the task is no longer necessary, so you must establish the condition on which to break out of this loop.
*	一个任务的run()方法通常有一些循环执行直到任务不再需要，因此你必须将条件建立在跳出这个循环的那个上。
*	Often, **run( )** is cast in the form of an infinite loop, which means that, barring some factor that causes **run( )** to terminate, it will continue forever.  
*	通常，run()以一个无限循环的形式强转，这意味着除非有些因子造成run()终止，否则它会一直继续下去。
*	To achieve threading behavior, you must explicitly attach a task to a thread.
*	为达到线程行为，你必须显式地将一个任务加到线程上。

###	The Thread class
*	The traditional way to turn a **Runnable** object into a working task is to hand it to a **Thread** constructor.
*	传统的将一个Runnable对象转为一个工作任务的方式是将其传给一个Thread构造函数。
*	Calling a **Thread** object’s **start( )** will perform the necessary initialization for the thread and then call that **Runnable**’s **run( )** method to start the task in the new thread.
*	调用一个Thread对象的start()方法会为线程执行必要的初始化，然后调用Runnable的run()方法来在新线程中开始任务。
*	This swapping is automatically controlled by the thread scheduler. If you have multiple processors on your machine, the thread scheduler will quietly distribute the threads among the processors.
*	这种交换由线程调度器自动控制，如果你的机器上有多个处理器，线程调度器将悄悄地将线程分布在处理器上。
*	The thread-scheduling mechanism is not deterministic.
*	线程调度机制不是决定性的。
*	You cannot plan on any consistent threading behavior. The best approach is to be as conservative as possible while writing threaded code.
*	你不能计划任何一致的线程行为，最好的方法是在写线程代码时尽可能保守点。
*	Each **Thread** "registers" itself so there is actually a reference to it someplace, and the garbage collector can’t clean it up until the task exits its **run( )** and dies.
*	每个线程注册自己以在某个地方有一个实际引用，垃圾回收不能在任务退出其run()方法及死亡之前清理。
*	A thread creates a separate thread of execution that persists after the call to **start( )** completes.
*	一个线程创建一个独立的执行线程，它会在对start()的调用完成之前一直存在。

###	Using Executors
*	**Executors** provide a layer of indirection between a client and the execution of a task; instead of a client executing a task directly, an intermediate object executes the task. 
*	Excutors在客户端和任务执行之间提供一个间接层，并非是一个客户直接执行一个任务，取而代之的是一个间接对象执行任务。
*	**Executors** allow you to manage the execution of asynchronous tasks without having to explicitly manage the lifecycle of threads. 
*	Executors允许你管理异步任务的执行而无需显式地管理线程的生命周期。
*	An **ExecutorService** knows how to build the appropriate context to execute **Runnable** objects.
*	一个ExecutorService知道如何建立合适的环境来执行Runnable对象。 
*	An **ExecutorService** object is created using a static **Executors** method which determines the kind of **Executor** it will be.
*	一个ExecutorService对象是用一个静态的决定Executor类型是什么的Executors方法创建的。
*	Very often, a single **Executor** can be used to create and manage all the tasks in your system.
*	通常，一个单独的Executor可以用来创建和管理你系统中的索引任务。
*	A **CachedThreadPool** will generally create as many threads as it needs during the execution of a program and then will stop creating new threads as it recycles the old ones, so it’s a reasonable first choice as an **Executor**.
*	一个CachedThreadPool一般会在程序执行期间创建它所需的的所有线程，然后在重利用旧线程时停止创建新的线程，因此它是Executor的第一合理选择。
*	If more than one task is submitted to a **SingleThreadExecutor**, the tasks will be queued and each task will run to completion before the next task is begun, all using the same thread.
*	 如果多个任务提交到一个SingleThreadExecutor,任务会入队然后每个任务将在下一个任务开始前完成，所有任务都使用相同的线程。
*	A **SingleThreadExecutor** serializes the tasks that are submitted to it, and maintains its own (hidden) queue of pending tasks.
*	一个SingleThreadExecutor序列化提交给它的任务，然后维护它自己的等待任务的(隐藏的)队列。
*	By serializing tasks, you can eliminate the need to serialize the objects.
*	通过序列化任务，你可以消除对序列化对象的需要。

###	Producing return values from tasks
*	If you want the task to produce a value when it’s done, you can implement the **Callable** interface rather than the **Runnable** interface. 
*	如果你想让任务在它完成时生成一个值，你可以实现Callable接口而非Runable接口。
*	**Callable** is a generic with a type parameter representing the return value from the method **call( )** (instead of **run( )**), and must be invoked using an **ExecutorService** **submit( )** method.
*	Callable是一个带有一个代表方法call()(而不是run())的返回值的类型参数的泛型，并且须用一个ExecutorService的submit()方法来实现。
*	The overloaded **Executors.callable( )** method takes a **Runnable** and produces a **Callable**. **ExecutorService** has some "invoke" methods that run collections of **Callable** objects.
*	重写的Executors.callable()方法输入一个Runnable并产生一个Callable,ExecutorService具有一些运行Callable对象集合的invoke方法。

###	Sleeping
*	Java SE5 introduced the more explicit version of **sleep( )** as part of the **TimeUnit** class, which provides better readability by allowing you to specify the units of the **sleep( )** delay.
*	Java SE5引入更显式版本的sleep()方法作为TimeUnit类的一部分，它允许你来指定sleep()延迟的单元来提供更佳的可读性。
*	If you must control the order of execution of tasks, your best bet is to use synchronization controls (described later) or, in some cases, not to use threads at all, but instead to write your own cooperative routines that hand control to each other in a specified order.  
*	如果你必须控制执行任务的顺序，你最好的赌注是使用同步控制，或者在一些情况下压根不用线程，取而代之的是写你自个的以一个特定顺序执行互相传递控制的程序。

###	Priority
*	Although the order in which the CPU runs a set of threads is indeterminate, the scheduler will lean toward running the waiting thread with the highest priority first.
*	尽管CPU运行一系列线程的顺序不是定的，调度器趋向于首先运行具有最高优先级的等待线程。 
*	Lower-priority threads just tend to run less often.
*	低优先级的线程趋向于更少运行。
*	Trying to manipulate thread priorities is usually a mistake.
*	试图操作线程优先级通常是错的。
*	You can read the priority of an existing thread with **getPriority( )** and change it at any time with **setPriority( )**.
*	你可以用getPriority()来读取一个已有线程的优先级并用setPriority()在任意时候改变它。
*	Although the JDK has 10 priority levels, this doesn’t map well to many operating systems.
*	尽管JDK具有10个优先级，但不能很好地映射到许多操作系统上。

###	Yielding
*	When you call **yield( )**, you are suggesting that other threads of the same priority might be run.
*	当你调用yield()时，你是在建议具有相同优先级的其他线程应该先运行。
*	In general, however, you can’t rely on **yield( )** for any serious control or tuning of your application.
*	但一般来说你不能在任何对你的应用的控制或调整上依靠yield()。

###	Daemon threads
*	A "daemon" thread is intended to provide a general service in the background as long as the program is running, but is not part of the essence of the program. 
*	一个守护进程是只要程序在运行提供就提供一个通用服务，但不是程序的基本部分。
*	Thus, when all of the non-daemon threads complete, the program is terminated, killing all daemon threads in the process. Conversely, if there are any non-daemon threads still running, the program doesn’t terminate.
*	这样，当所有的非守护进程完成后，程序就终止了杀死进程中的所有守护进程，相反，若是有非守护进程仍在运行，程序将不会终止。
*	You must set the thread to be a daemon by calling **setDaemon( )** before it is started. 
*	你必须在一个线程启动前通过调用setDaemon()来设置它为守护线程。
*	It is possible to customize the attributes (daemon, priority, name) of threads created by **Executors** by writing a custom **ThreadFactory**.
*	可以通过写一个一般的ThreadFactory来指定由Executor创建的线程的属性(守护，优先级，名称)。
*	Each of the static **ExecutorService** creation methods is overloaded to take a **ThreadFactory** object that it will use to create new threads.
*	每个静态的ExecutorService创建方法被重写了，带一个ThreadFactory对象用于创建新的线程。
*	If a thread is a daemon, then any threads it creates will automatically be daemons.
*	如果一个线程是一个守护线程，那么它创建的任何线程将自动是守护线程。
*	You should be aware that daemon threads will terminate their **run( )** methods without executing **finally** clauses.
*	你要意识到守护线程将在不执行finally子句的情况下终止它们的run()方法。
*	Daemons are terminated "abruptly" when the last of the non-daemons terminates. So as soon as **main( )** exits, the JVM shuts down all the daemons immediately, without any of the formalities you might have come to expect.
*	守护线程会在最后一个非守护线程终止后立即终止，所以只要main()方法退出，JVM立即杀死所有守护线程，不会有任何你可能会期待的礼节。

###	Coding variations
*	In very simple cases, you may want to use the alternative approach of inheriting directly from **Thread**.
*	在非常简单的情况下，你可能想用另一种直接继承Thread的方法。
*	You should be aware that starting threads inside a constructor can be quite problematic, because another task might start executing before the constructor has completed, which means the task may be able to access the object in an unstable state.
*	你要意识到在一个构造函数内部启动一个线程可能会相当有问题，因为另一个任务可能会在构造函数完成之前开始执行，这意味着任务可能访问一个不稳定状态的对象。
*	Sometimes it makes sense to hide your threading code inside your class by using an inner class.
*	有时候将你的线程用一个内部类隐藏在你的类中比较合理。

###	Terminology
*	There’s a distinction between the task that’s being executed and the thread that drives it.
*	在被执行的任务和驱动它的线程间有差异。
*	You create tasks and somehow attach a thread to your task so that the thread will drive that task.
*	你创建一个任务并以某种方式将一个线程附加到你的任务上来让线程驱动该任务。
*	In Java, the **Thread** class by itself does nothing. It drives the task that it’s given.
*	Java中，Thread类自己并不做啥，它驱动给它的任务。
*	If the interface is clearly nothing more than a generic encapsulation of its methods, then the "it-does-this-thing-**able**" naming approach is appropriate, but if it intends to express a higher concept, like **Task**, then the concept name is more helpful. 
*	如果接口明显不过是其方法的一个泛型封装，那么“***able”的命名方法是合适的，但如果它要表达更高层次的概念，比如Task，纳米概念名会更有帮助。
*	It makes sense from an implementation standpoint to separate tasks from threads.
*	从实现的角度来说，将任务从线程分离是合理的。
*	To stay at a higher level of abstraction, you must use discipline when writing code.
*	站在抽象的更高层次，你必须在写代码时使用规则。
*	If you are discussing a system at a conceptual level, you could just use the term "task" without mentioning the driving mechanism at all.  
*	如果你是在一个概念的层次讨论一个系统，你可以只用task而压根不提驱动机制。

###	Joining a thread
*	If a thread calls **t.join( )** on another thread **t**, then the calling thread is suspended until the target thread **t** finishes. 
*	如果一个线程在另一个线程t上调用t.join()方法，那么调用线程会阻塞知道目标线程t完成。

###	Catching exceptions
*	Because of the nature of threads, you can’t catch an exception that has escaped from a thread.
*	由于线程的性质，你不能捕获一个从一个线程逃掉了的异常。
*	**Thread.UncaughtExceptionHandler** is a new interface in Java SE5; it allows you to attach an exception handler to each **Thread** object. **Thread.UncaughtExceptionHandler.uncaughtException( )** is automatically called when that thread is about to die from an uncaught exception. 
*	Thread.UncaughtExceptionHandler是Java5中的一个新接口，它允许你给每个Thread对象附加一个异常处理器。Thread.UncaughtExceptionHandler.uncaughtException()会在该线程将从一个未捕获异常死亡时自动被调用。

##	Sharing resources
*	You now have the possibility of two or more tasks interfering with each other.
*	你现在可能有两个或多个相互干扰的任务。

###	Improperly accessing resources
*	It is atomic, which means that simple operations like assignment and value return happen without the possibility of interruption.
*	它是原子的，意味着简单的像赋值和值返回不可能被中断。
*	*race condition:* two or more tasks race to respond to a condition and thus collide or otherwise produce inconsistent results. 	 
*	竞争条件：两个或多个任务对一个条件的响应进行竞争并因此冲突或产生不一致的结果。
*	This is part of the problem with multithreaded programs—they can appear to be correct even when there’s a bug, if the probability for failure is very low.
*	这是多线程编程的部分问题，即使有Bug它们看起来也是正确的，如果错误的比例非常低的话。
*	Increment is not an atomic operation in Java. So even a single increment isn’t safe to do without protecting the task.
*	Java中的加法不是一个原子操作，因此即使是一个单独加法在没有保护任务的情况下也不是安全的。

###	Resolving shared resource contention
*	For concurrency to work, you need some way to prevent two tasks from accessing the same resource, at least during critical periods.
*	对于并发工作，你需要一种方法阻止两个任务访问相同的资源，至少是在重要周期。
*	To solve the problem of thread collision, virtually all concurrency schemes *serialize access* to *shared resources*.
*	要解决线程冲突的问题，所有的并发都序列访问共享资源。
*	Suggestions can be made to the thread scheduler via **yield( )** and **setPriority( )**, but these suggestions may not have much of an effect, depending on your platform and JVM implementation.
*	通过yield()和setPriority()可以向线程调度器建议，但这些建议可能没啥卵用，这取决于你的平台和虚拟机实现。 
*	To prevent collisions over resources, Java has built-in support in the form of the **synchronized** keyword. When a task wishes to execute a piece of code guarded by the **synchronized** keyword, it checks to see if the lock is available, then acquires it, executes the code, and releases it.
*	要防止资源冲突，Java有内置的synchronized关键字支持，当一个任务想要执行收synchronized保护的代码段时，它会检查锁是否可用，然后接受它，执行代码，最后释放它。
*	To control access to a shared resource, you first put it inside an object. Then any method that uses the resource can be made **synchronized**.
*	要控制对一个共享资源的访问，你首先将它放到一个对象中，然后使用资源的任何方法可以设为synchronized的。
*	If a task is in a call to one of the **synchronized** methods, all other tasks are blocked from entering any of the **synchronized** methods of that object until the first task returns from its call.
*	如果一个任务是对synkhronized方法的调用之一，所有其他任务都阻塞于进入该对象的任何synchronized方法，直到第一个任务返回其调用。
*	When you call any **synchronized** method, that object is locked and no other **synchronized** method of that object can be called until the first one finishes and releases the lock.  
*	当你调用任何synchronized方法时，其他对象都被锁住并且没有该对象的其他synchronized方法可以调用，直到第一个完成并释放该锁。
*	Note that it’s especially important to make fields **private** when working with concurrency; otherwise the **synchronized** keyword cannot prevent another task from accessing a field directly, and thus producing collisions.
*	注意在用并发时让字段私有尤为重要，否则synchronized关键字不能阻止另一个任务直接访问字段，并由此造成冲突。
*	The JVM keeps track of the number of times the object has been locked. If the object is unlocked, it has a count of zero. As a task acquires the lock for the first time, the count goes to one. Each time the same task acquires another lock on the same object, the count is incremented. 
*	虚拟机追踪记录对象锁住的次数，如果对象没有被锁，它计数为0，当一个任务第一次需要锁时，计数变为1，每次相同的任务从相同的获取另一个锁时，计数增加。
*	There’s also a single lock per class (as part of the **Class** object for the class), so that **synchronized** **static** methods can lock each other out from simultaneous access of **static** data on a class-wide basis.
*	每个类也有一个单独的锁(就像是类的Class对象部分)，因此synchronized static方法可以互相锁住对方同时访问类范围的静态数据。
*	If you have more than one method in your class that deals with the critical data, you must synchronize all relevant methods.
*	如果你的类中有超过一个的处理重要数据的方法，你必须对所有相关方法同步。
*	Every method that accesses a critical shared resource must be **synchronized** or it won’t work right.
*	每个访问一个重要资源的方法必须是synchronized的，否则它根本没用。

###	Using explicit Lock objects
*	The **Lock** object must be explicitly created, locked and unlocked; thus, it produces less elegant code than the built-in form. 
*	Lock对象必须显式创建，加锁然后释放锁，这样，它产生的代码没用内置形式那么优雅漂亮。
*	Right after the call to **lock( )**, you must place a **try-finally** statement with **unlock( )** in the **finally** clause.
*	调用lock()后，你必须放一个try-finally语句，并在finally子句中用unlock()方法。
*	The **return** statement must occur inside the **try** clause to ensure that the **unlock( )** doesn’t happen too early and expose the data to a second task.
*	return语句必须发生在try语句内部来确保unlock()方法不会过早发生并暴漏数据给第二个任务。
*	With explicit **Lock** objects, you can maintain proper state in your system using the **finally** clause.
*	有了显式的Lock对象，你可以用finnaly子句维护系统的合适状态。
*	You’ll usually only use the explicit **Lock** objects when you’re solving special problems.
*	在你解决特殊问题时，你通常只用显式的Lock对象。
*	The explicit **Lock** object also gives you finer-grained control over locking and unlocking than does the built-in **synchronized** lock. 
*	显式的Lock对象也会给你比内置synchronized锁更精确的对加锁和释放锁的控制。

###	Atomicity and volatility
*	You should only try to use atomicity instead of synchronization if you are a concurrency expert.
*	如果你是一个并发专家的话你应当只用原子操作来代替同步。
*	The JVM is allowed to perform reads and writes of 64-bit quantities (long and double variables) as two separate 32-bit operations, raising the possibility that a context switch could happen in the middle of a read or write, and then different tasks could see incorrect results. 
*	虚拟机允许进行读写64位(long和double型变量)和两个分离的32位的操作，增加了一次上下文转换可能发生在一次读写期间的可能性，然后不同的任务可能看到错误的结果。
*	You do get atomicity (for simple assignments and returns) if you use the **volatile** keyword when defining a long or double variable.
*	如果你用volatile关键字定义一个long或double类型的变量，你就获得了原子性(对于简单的赋值和返回)。
*	The **volatile** keyword also ensures visibility across the application. If you declare a field to be **volatile**, this means that as soon as a write occurs for that field, all reads will see the change.
*	volatile关键字也保证了整个应用的可见性，如果你声明一个字段为volatile的，这意味着在对该字段写之后，所有的读都会看到改变。
*	**volatile** fields are immediately written through to main memory, and reads occur from main memory.
*	volatitle字段立即写入到主存，然后读从主存发生。
*	If multiple tasks are accessing a field, that field should be **volatile**; otherwise, the field should only be accessed via synchronization.
*	如果多个任务在访问一个字段，那个字段就应当是volatile的，否则的话，字段应当只能通过同步访问。
*	Your first choice should be to use the **synchronized** keyword.
*	你的第一选择应当是使用synchronized关键字。
*	If you define a variable as volatile, it tells the compiler not to do any optimizations that would remove reads and writes that keep the field in exact synchronization with the local data in the threads.
*	如果你将一个变量定义为volatile的，它将告诉编译器不要做任何可能移除读写的优化，这些读写操作用线程中的本地数据保持字段恰好同步。
*	**volatile** also restricts compiler reordering of accesses during optimization.
*	volatile也限制了编译器在优化期间重新排序访问。
*	The atomic operations that are supposed to be safe are the reading and assignment of primitives.
*	读以及对基本类型赋值这样的原子操作应当是安全的。
*	It’s still easily possible to use an atomic operation that accesses your object while it’s in an unstable intermediate state.  
*	在它还是个不稳定的中间状态时，用一个原子操作访问你的对象依然是很有可能的。

###	Atomic classes
*	It should be emphasized that the **Atomic** classes were designed to build the classes in **java.util.concurrent**, and that you should use them in your own code only under special circumstances, and even then only when you can ensure that there are no other possible problems.
*	应当强调Atomic类是设计用来建立java.util.cocurrent中的类的，你应当只在特殊情况下子啊你自己的代码中使用它们，即便是那时你也得在能保证没有其他可能问题时用。

###	Critical sections
*	Sometimes, you only want to prevent multiple thread access to part of the code inside a method instead of the entire method.
*	有时，你只想阻止多线程访问方法中的部分代码而非整个方法。
*	Note that the **synchronized** keyword is not part of the method signature and thus may be added during overriding.
*	注意synchronized关键字不是方法标识符的部分，因此可以在重写的时候加上去。
*	This is typically the reason to use a **synchronized** block instead of synchronizing the whole method: to allow other tasks more access (as long as it is safe to do so).
*	这正是用一个synchronized块而非同步整个方法的原因：让其他任务更多访问(只要这样做是安全的)。

###	Synchronizing on other objects
*	when the lock is acquired for the **synchronized** block, other **synchronized** methods and critical sections in the object cannot be called. 
*	当lock是由sychronize块获取的，对象中的其他synchronized方法及重要部分就不能被调用。
*	Sometimes you must synchronize on another object, but if you do this you must ensure that all relevant tasks are synchronizing on the same object. 
*	有时你必须在另一个对象上同步，但如果你这么做的话你必须得保证所有相关任务在相同对象上是同步的。

###	Thread local storage
*	Thread local storage is a mechanism that automatically creates different storage for the same variable, for each different thread that uses an object.
*	线程本地存储是一种自动为使用一个对象的不同线程的相同变量创建不同存储的机制。
*	If you have five threads using an object with a variable x, thread local storage generates five different pieces of storage for x.
*	如果你有五条线程使用一个具有变量x的对象，线程本地存储会为x产生五个不同的存储区。
*	The creation and management of thread local storage is taken care of by the **java.lang.ThreadLocal** class.
*	线程本地存储的创建和管理由java.lang.ThreadLical类操心。
*	**ThreadLocal** objects are usually stored as **static** fields. When you create a **ThreadLocal** object, you are only able to access the contents of the object using the **get( )** and **set( )** methods.
*	ThreadLocal对象通常存储位static字段，当你创建一个ThreadLocal对象时，你只能用get()和set()方法访问对象内容。
*	**ThreadLocal** guarantees that no race condition can occur. 
*	ThreadLocal保证了没有竞争条件会发生。

##	Terminating tasks
*	In real threading problems, the possibility for failure may be statistically small, so you can easily fall into the trap of believing that things are working correctly. 	
*	在实际的线程问题中，失败的可能在统计上也许不大，因此你可能轻易会掉进相信一切都工作正常的陷阱中。
*	there are likely to be hidden problems that haven’t occurred to you, so be exceptionally diligent when reviewing concurrent code.
*	有可能有潜在问题没发生在你那里，因此在检测并发代码时要非常谨慎。


###	Terminating when blocked
*	sleep( ) is just one situation where a task is blocked from executing, and sometimes you must terminate a task that’s blocked.
*	sleep()只是一种任务阻塞执行的状况，有时你必须终止一个阻塞的任务。
*	A thread can be in any one of four states:
*	一个线程可以处在以下任意四种状态之一：
		
		New：	it becomes eligible to receive CPU time.
		New： 	它可以接收CPU时间； 
		Runnable: 	a thread can be run when the time-slicing mechanism has CPU cycles available for the thread.
		Runnable:	一个线程可以在时间片机制对该线程有CPU循环时运行；
		Blocked: 	 the scheduler will simply skip it and not give it any CPU time.
		Blocked：	调度器只是简单地跳过它，并不给它任何CPU时间； 
		Dead:	A thread is no longer schedulable and will not receive any CPU time.
		Dead:	一个线程不再是可调度的并且不会接收任何CPU时间。 

*	Becoming blocked：	You’ve put the task to sleep；You’ve suspended the execution of the thread； waiting for some I/O to complete；call a **synchronized** method.
*	进入阻塞： 将任务置于睡眠，将线程的执行悬挂起来，等待IO结束，调用一个synchronized方法。


###	Interruption
*	If you’re using **Executor**s, you can hold on to the context of a task when you start it by calling **submit( )** instead of **execute( )**.
*	如果你是在用Executor，你可以通过在启动它时调用submit()而不是execute()保持任务的上下文。
*	I/O and waiting on a **synchronized** lock are not interruptible.
*	IO以及等待一个synchronized锁是不可中断的。
*	You can interrupt a call to **sleep( )** (or any call that requires you to catch **InterruptedException**). However, you cannot interrupt a task that is trying to acquire a **synchronized** lock or one that is trying to perform I/O.
*	你可以中断一个对sleep()的调用(或者任何需要你捕获InterruptedException的调用)，但是，你不能中断一个正在尝试获取一个synchronized锁的任务或者一个正在尝试执行IO的任务。
*	Blocked nio channels automatically respond to interrupts.
*	阻塞的nio通道自动对中断作出响应。
*	One of the features added in the Java SE5 concurrency libraries is the ability for tasks blocked on **ReentrantLock**s to be interrupted, unlike tasks blocked on **synchronized** methods or critical sections.
*	Java5的并发库中新增的特征之一是让阻塞在ReentrantLock的任务中断的能力，不像阻塞在synchronized方法或重要部分上的任务。

###	Checking for an interrupt
*	If you call **interrupt( )** to stop a task, your task needs a second way to exit in the event that your **run( )** loop doesn’t happen to be making any blocking calls.
*	如果你调用interrupt()来停止一个任务，你的任务需要另一种方法退出run()循环没有进行任何阻塞调用的事件。
*	You check for the interrupted status by calling **interrupted( )**.
*	你通过调用interrupted()来检测中断状态。
*	Clearing the interrupted status ensures that the framework will not notify you twice about a task being interrupted.
*	清除中断状态确保框架不会为一个任务中断通知你两次。
*	A class designed to respond to an **interrupt( )** must establish a policy to ensure that it will remain in a consistent state.  
*	一个设计用来响应一个interrupt()的类必须建立一种规则来确保它会保持在一种一致状态。
*	The creation of all objects that require cleanup must be followed by **try-finally** clauses so that cleanup will occur regardless of how the **run( )** loop exits. 
*	创建需要清理的所有对象必须后面跟上try-finally子句以让清理不管run()循环怎么退出也能发生。
*	It relies on the client programmer to write the proper **try-finally** clauses.
*	写出合适的try-finally自己依赖于客户程序员。

##	Cooperation between tasks
*	If two tasks are stepping on each other over a shared resource (usually memory), you use a mutex to allow only one task at a time to access that resource.
*	如果两个任务互相阻塞在一个共享资源上(通常是内存)，你使用一个信号量来使得一次只有一个任务访问该资源。
*	Now the issue is not about interfering with one another, but rather about working in unison, since portions of such problems must be solved before other portions can be solved.
*	现在问题不在于与另一个相互冲突，而在于一起协作，因为这个问题的一部分必须在另一部分可以被解决前解决。
*	The key issue when tasks are cooperating is handshaking between those tasks.
*	 任务合作时的关键问题是在这些任务间的握手。
*	In this case guarantees that only one task can respond to a signal.
*	在这种情况保证了只有一个任务可以响应一个信号。

###	wait() and notifyAll()
*	 So **wait( )** suspends the task while waiting for the world to change, and only when a **notify( )** or **notifyAll( )** occurs—suggesting that something of interest may have happened—does the task wake up and check for changes.
*	 因此wait()在等待世界改变的时候挂起任务，并且只有一个notify()或notifyAll()——意味着有感兴趣的事可能发生了——发生时任务才会唤醒并检查变化。 
*	 when a task enters a call to **wait( )** inside a method, that thread’s execution is suspended, and the lock on that object is released. 
*	 当一个任务在一个方法中进入一个对wait()的调用，该线程的执行挂起，并且释放该对象上的锁。
*	 Because **wait( )** releases the lock, it means that the lock can be acquired by another task, so other **synchronized** methods in the (now unlocked) object can be called during a **wait( )**.
*	 由于wait()释放了锁，意味着锁可以被另一个任务获得，因此在一个wait()对象(现在没锁了)中的其他synchronized方法可以被调用。
*	 The only place you can call **wait( )**, **notify( )**, or **notifyAll( )** is within a **synchronized** method or block.
*	 你可以调用wait()，notify()或notifyAll()的唯一地方是在一个synchronized方法或块中。
*	 You can ask another object to perform an operation that manipulates its own lock.
*	 你可以请求另一个对象来执行一个操作它自己的锁的操作。
*	 In order for the task to wake up from a **wait( )**, it must first reacquire the lock that it released when it entered the **wait( )**. The task will not wake up until that lock becomes available.
*	 为了将任务从一个wait()中唤醒，它必须首先获取它在进入wait()时释放的锁，任务在锁可以用之前不会唤醒。
*	 You must surround a **wait( )** with a while loop that checks the condition(s) of interest.
*	 你必须将一个wait()放在一个检查感兴趣的条件的while循环中。
*	 When two threads are coordinated using **notify( )/wait( )** or **notifyAll( )/wait( )**, it’s possible to miss a signal.
*	 当两个线程用notify()/wait()或notifyAll()/wait()合作时，有可能丢失一个信号。

###	notify() vs. notifyAll()
*	Only one task of the possible many that are waiting on a lock will be awoken with **notify( )**, so you must be certain that the right task will wake up if you try to use **notify( )**.
*	在众多的等待一个锁的可能的任务中，只有一个会被notify()唤醒，因此在试图用notify()时，你必须保证正确的任务会被唤醒。
*	All tasks must be waiting on the same condition in order for you to use **notify( )**, because if you have tasks that are waiting on different conditions, you don’t know if the right one will wake up.  
*	为了让你使用notify()，所有任务必须等在相同的条件下，因为如果有等在不同条件下的任务，你不知道是不是正确的那个会被唤醒。
*	If you use **notify( )**, only one task must benefit when the condition changes.
*	如果你用notify()，在条件改变时，只有一个任务可能受益。
*	only the tasks that are waiting on a particular lock are awoken when **notifyAll( )** is called for that lock.
*	只有在等待一个特定锁的任务会在为这个锁调用notifyAll()时被唤醒。

###	Producers and consumers
*	However, in more complex situations, multiple tasks may be waiting on a particular object lock, so you don’t know which task should be awakened. Thus, it’s safer to call **notifyAll( )**, which wakes up all the tasks waiting on that lock.
*	但是，在更复杂的情况下，多个任务可能在等一个特定的对象锁，因此你不知道哪个任务会被唤醒，这样，调用notifyAll()是安全的，它会唤醒所有等待该锁的任务。
*	Because the lock must be owned in order for **notifyAll( )** to be called, it’s guaranteed that two tasks trying to call **notifyAll( )** on one object won’t step on each other’s toes.
*	因为锁必须为了让notifyAll()被调用而拥有，需保证两个试图在一个对象上调用notifyAll()的任务不会相互阻塞。
*	In a typical producerconsumer implementation, you use a first-in, first-out queue in order to store the objects being produced and consumed. 
*	在一个典型的生产者消费者的实现中，你用一个先入先出的队列来存储被生产和消费的对象。

###	Using explicit Lock and Condition objects
*	You can suspend a task by calling **await( )** on a **Condition**.
*	你可以通过在一个Condition上调用await()挂起一个任务。
*	When external state changes take place that might mean that a task should continue processing, you notify the task by calling **signal( )**, to wake up one task, or **signalAll( )**, to wake up all tasks that have suspended themselves on that **Condition** object.
*	当外部状态改变发生时，这可能意味着一个任务应当继续处理，你调用signal来通知任务唤醒一个任务，或是调用signalAll()唤醒在该Condition对象上挂起自己的所有任务。
*	The **Condition** object contains no information about the state of the process.
*	Condition对象不包含关于进程状态的信息。
*	The **Lock** and **Condition** objects are only necessary for more difficult threading problems.
*	Lock和Condition对象只对更复杂的线程问题是必要的。

###	Producer-consumers and queues
*	 In many cases, you can move up a level of abstraction and solve task cooperation problems using a synchronized queue, which only allows one task at a time to insert or remove an element.
*	 在很多情况下，你可以上移一层抽象，并用一个同步队列解决任务的合作问题，它只允许一次插入或删除一个任务。
*	 You’ll usually use the **LinkedBlockingQueue**, which is an unbounded queue; the **ArrayBlockingQueue** has a fixed size, so you can only put so many elements in it before it blocks. 
*	 你通常会用LinkedBlockingQueue，这是一个无界的队列，ArrayBlockingQueue只有固定的大小，因此你只能在其阻塞前放入这么多元素。
*	 Blocking queues can solve a remarkable number of problems in a much simpler and more reliable fashion than **wait( )** and **notifyAll( )**.
*	 阻塞队列可以用一种比wait()和notifyAll()更简单可靠的方式解决大量的问题。
*	The coupling between the classes that would exist with explicit **wait( )** and **notifyAll( )** statements is eliminated because each class communicates only with its **BlockingQueue**s.
*	与显式wait()和notifyAll()语句一起存在的类间的耦合被消除了，因为每个类只跟它的BlokingQueue通信。

###	Using pipes for I/O between tasks
*	It’s often useful for tasks to communicate with each other using I/O. Threading libraries may provide support for inter-task I/O in the form of pipes. 
*	通常用让任务通过I/O互相交流非常有用，线程库可能为内部任务以管道的形式提供支持。
*	The pipe is basically a blocking queue, which existed in versions of Java before **BlockingQueue** was introduced.
*	管道基本上是一个阻塞队列，它存在于引入BlockingQueue之前的Java版本。
*	the **PipedReader** is interruptible, whereas if you changed, the **interrupt( )** would fail to break out of the **read( )** call.
*	PipeReader可以中断，但是如果你改变了，interrupt()会在跳出read()调用时失败。

##	Deadlock
*	You get a continuous loop of tasks waiting on each other, and no one can move.
*	你得到了一个任务互相等待的无限循环，没一个可以动。
*	The real problem is when your program seems to be working fine but has the hidden potential to deadlock.
*	实际问题是你的程序看起来可以工作，但有形成死锁的潜在可能性。
*	Preventing deadlock through careful program design is a critical part of developing concurrent systems.
*	通过仔细的编程设计防止死锁是开发并发系统的一个重要部分。
*	A program can appear to run correctly but actually be able to deadlock.
*	一个程序看上去可以正常运行，但实际上可能形成死锁。
*	Deadlock can occur if four conditions are simultaneously met:
*	死锁会在四个条件同时发生时产生：

		a. Mutual exclusion. At least one resource used by the tasks must not be shareable.
		a. 互斥访问，任务用到的资源至少有一个是不能共享的； 
		b. At least one task must be holding a resource and waiting to acquire a resource currently held by another task.
		b.至少有一个任务必须持有一个资源并等待获取一个正被其他任务持有的资源；
		c. A resource cannot be preemptively taken away from a task. Tasks only release resources as a normal event.
		c. 一个资源不能从一个任务先被强占，任务只将锁以一种正常事件释放；
		d. A circular wait can happen.
		d.一个环形等待发生。
*	You only need to prevent one of them from occurring to prohibit deadlock.
*	你只需阻止其中之一发生来防止死锁。
*	There is no language support to help prevent deadlock; it’s up to you to avoid it by careful design.
*	没有防止死锁的语言支持，要靠你的仔细设计来避免它。

##	New library components
*	The **java.util.concurrent** library in Java SE5 introduces a significant number of new classes designed to solve concurrency problems.
*	java se5中的java.util.concurrent库引入了大量的新设计的类来解决并发问题。

###	CountDownLatch
*	This is used to synchronize one or more tasks by forcing them to wait for the completion of a set of operations being performed by other tasks.
*	该类通过强制它们等待等待一系列被其他任务执行的操作完成来同步一个或多个任务。
*	You give an initial count to a **CountDownLatch** object, and any task that calls **await( )** on that object will block until the count reaches zero.
*	你给一个CountDownLatch对象一个初始计数，任何在该对象上调用await()的任务会阻塞到计数值变为0； 
*	A **CountDownLatch** is designed to be used in a one-shot fashion; the count cannot be reset. If you need a version that resets the count, you can use a **CyclicBarrier** instead.
*	一个CountDownLatch被设计为一次性使用，计数不能重置，如果你需要一个重置计数的版本，你可以用一个CyclicBarrier代替它；
*	A typical use is to divide a problem into n independently solvable tasks and create a **CountDownLatch** with a value of n.
*	一个典型的使用方法将一个任务分解为n个独立可解的任务，并创建一个具有n值的CountDownLatch;
*	It happens that **Random.nextInt( )** is thread-safe, but alas, you shall have to discover this on a case-by-case basis, using either a Web search or by inspecting the Java library code.
*	恰好Random.nextInt()是线程安全的，然而，你得用Web搜索或检查Java库的源码在一个具体基类中发现它。

###	CyclicBarrier
*	A **CyclicBarrier** is used in situations where you want to create a group of tasks to perform work in parallel, and then wait until they are all finished before moving on to the next step.
*	一个CyclicBarrier用于你想创建一组并行执行的任务，然后一直等待直到它们在进行到下一步前全部完成。
*	A **CountDownLatch** is a one-shot event, whereas a **CyclicBarrier** can be reused over and over.
*	一个CountDownLatch是一个一次性事件，而一个CyclicBarrier可以一次又一次地重用。
*	A **CyclicBarrier** can be given a "barrier action," which is a **Runnable** that is automatically executed when the count reaches zero—this is another distinction between **CyclicBarrier** and **CountdownLatch**.
*	可以给CyclicBarrier一个barrier action,它是一个在计数到达零时自动执行的Runnable，这是CyclicBarrier和CountdownLatch间的另一个差别。 

###	DelayQueue
*	This is an unbounded **BlockingQueue** of objects that implement the **Delayed** interface.
*	这是一个无界的实现了Delayed接口的BlockingQueue对象。
*	An object can only be taken from the queue when its delay has expired. The queue is sorted so that the object at the head has a delay that has expired for the longest time.
*	一个对象只在其延迟达到时才能从队中取出，队列是排序的以让队首的对象具有最长的失效时间。
*	If no delay has expired, then there is no head element and **poll( )** will return **null**.
*	如果没有延迟失效，就没有队首元素，因而poll()将返回null。
*	**DelayQueue** is thus a variation of a priority queue.
*	所有DelayQueue是一个优先队列的变种。

###	PriorityBlockingQueue
*	This is basically a priority queue that has blocking retrieval operations.
*	该类基本上是一个具有阻塞恢复操作的优先队列
*	You don’t have to think about whether the queue has any elements in it when you’re reading from it, because the queue will simply block the reader when it is out of elements.
*	在你读取时无需考虑队中是不是有元素，因为队列会在没有元素时简单地阻塞；

###	The greenhouse controller with ScheduledExecutor
*	The **ScheduledThreadPoolExecutor** provides just the service necessary to solve the problem. Using either **schedule( )** (to run a task once) or **scheduleAtFixedRate( )** (to repeat a task at a regular interval), you set up **Runnable** objects to be executed at some time in the future. 
*	ScheduledThreadPoolExecutor提供了解决问题的必要服务，用schedule()（每次执行一个任务）或scheduleAtFixedRate()(以固定时间段重复一个任务)，你设置在将来某个时间要执行的Runnable对象。

###	Semaphore
*	A normal lock (from **concurrent.locks** or the built-in **synchronized** lock) only allows one task at a time to access a resource.
*	一个正常的锁(来自concurrent.locks或是内置的synchronized锁)每次只允许一个任务访问资源。
*	A *counting semaphore* allows n tasks to access the resource at the same time.
*	一个计数信号允许n个任务同时访问一个资源。
*	You can also think of a semaphore as handing out "permits" to use a resource, although no actual permit objects are used.
*	你也可以将一个信号看作是使用一个资源的permits，尽管没有实际的permit对象被使用。

###	Exchanger
*	An **Exchanger** is a barrier that swaps objects between two tasks.
*	一个Exchanger是一个在两个任务间交换对象的栅栏。
*	When the tasks enter the barrier, they have one object, and when they leave, they have the object that was formerly held by the other task. 
*	当任务进入栅栏时，它们有一个对象，当它们离开时，它们拥有之前被其他任务所有的对象。
*	**Exchangers** are typically used when one task is creating objects that are expensive to produce and another task is consuming those objects; this way, more objects can be created at the same time as they are being consumed.
*	Exchangers通常在一个任务创建产生起来代价大的对象并且另一个任务消费这些对象的情况下使用，这样，多个对象可以在它们被消费时创建。

##	Simulation
*	Using concurrency, each component of a simulation can be its own task, and this makes a simulation much easier to program.
*	使用并发，一个模拟的每个部分可以是它自己的任务，这使得一个模拟对程序来说更简单。

###	Bank teller simulation
*	This classic simulation can represent any situation where objects appear randomly and require a random amount of time to be served by a limited number of servers. 
*	这种典型的模拟可以代表任何对象随机出现及获取一个由有限数量的服务器服务随机数量时间的情况。
*	It’s possible to build the simulation to determine the ideal number of servers.
*	有可能建立模拟来决定理想数量的服务器。
*	All control systems have stability issues; if they react too quickly to a change, they are unstable, and if they react too slowly, the system moves to one of its extremes.
*	所有的控制系统有稳定问题，如果它们对一个变化反应太快，它们就是不稳定的，而如果它们反应太慢，系统又走向了另一个极端。

###	The restaurant simulation
*	**SynchronousQueue** is a blocking queue that has no internal capacity, so each **put( )** must wait for a **take( )**, and vice versa.
*	synchronousQueue是一个没有内部容量的阻塞队列，因此每个put()必须等待一个take()，反之亦然。
*	The management of complexity using queues to communicate between tasks greatly simplifies the process of concurrent programming by inverting the control: The tasks do not directly interfere with each other. Instead, the tasks send objects to each other via queues. 
*	用队列在任务间通信的复杂性的管理通过控制反转大大简化了并发编程的过程，任务不会直接互相干扰，相反，任务通过队列互相发送对象。
*	The receiving task handles the object, treating it as a message rather than having the message inflicted upon it.
*	接收任务处理对象，将其作为一个信息对待而不是将信息强加在它上边。

##	Performance tuning
###	Comparing mutex technologies
*	It is fairly clear that using **Lock** is usually significantly more efficient than using **synchronized**, and it also appears that the overhead of **synchronized** varies widely, while **Lock**s are relatively consistent.
*	很明显使用Lock通常比使用synchronized更高效，同时过量的synchronize的开销变化大，而Lock相对一致一些。
*	So the percentage of time in the body will probably be significantly bigger than the overhead of entering and exiting the mutex, and could overwhelm any benefit of speeding up the mutex.
*	因此Body中时间的百分比可能比进入和退出同步的开销大很多，并且可能超过加速同步的任何好处。
*	The **synchronized** keyword produces much more readable code than the lock **try/finally**-unlock idiom that **Lock**s require.
*	synchronized关键字比加锁try/finally释放锁条目产生可读性更好的代码。
*	It makes sense to start with the **synchronized** keyword and only change to **Lock** objects when you are tuning for performance.
*	用synchronized关键字开始并只在你调节性能时转为Lock对象是比较合理的。
*	**Atomic** objects are only useful in very simple cases, generally when you only have one **Atomic** object that’s being modified and when that object is independent from all other objects.
*	Atomic对象只在非常简单的情形下有用，一般是你只有一个Atomic对象被修改而该对象独立于其他所有对象时。
*	It’s safer to start with more traditional mutexing approaches and only attempt to change to **Atomic** later, if performance requirements dictate. 
*	以更传统的互斥方法开始并在稍后转为Atomic会更安全，如果涉及性能需要。

###	Lock-free containers
*	In Java 1.2, the **Collections** class was given various **static** "synchronized" decoration methods to synchronize the different types of containers.
*	Java1.2中，Collections类中被赋予了多种static synchronized装饰方法来同步不同类型的容器。
*	Java SE5 has added new containers specifically to increase thread-safe performance, using clever techniques to eliminate locking.
*	Java SE5中增加了新的特别为增加线程安全性能容器，使用更聪明的技术来消除锁。
*	 A modification is performed on a separate copy of a portion of the data structure (or sometimes a copy of the whole thing), and this copy is invisible during the modification process.
*	 在一个独立的部分数据结构的拷贝(或者有时是完整拷贝)上执行了，并且该拷贝在改变进程期间是不可见的。
*	 Only when the modification is complete is the modified structure atomically swapped with the "main" data structure, and after that readers will see the modification.
*	 只有当改变完成，修改的结构才会自动与main数据结构交换，并且之后读者会看到改变。
*	 In **CopyOnWriteArrayList**, a write will cause a copy of the entire underlying array to be created.
*	 在CopyOnWriteArrayList中，一个写会造成一个底层数组的整个拷贝被创建。
*	 **CopyOnWriteArraySet** uses **CopyOnWriteArrayList** to achieve its lock-free behavior.
*	 CopyOnWriteArraySet使用CopyOnWriteArrayList来达到其无须锁功能
*	 **ConcurrentHashMap** and **ConcurrentLinkedQueue** use similar techniques to allow concurrent reads and writes, but only portions of the container are copied and modified rather than the entire container.
*	 ConcurrentHashMap和ConcurrentLinkedQueue使用相似的技术来允许并发读写，但只有容器的部分被拷贝和改写而不是整个容器。  

###	Performance issues
*	As long as you are primarily reading from a lock-free container, it will be much faster than its **synchronized** counterpart because the overhead of acquiring and releasing locks is eliminated. 
*	只有你是主要从一个lock-free容器读，就比其对应的synchronized快，因为对获取和释放锁的开销被消除了。
*	You can see that a **synchronized** **ArrayList** has roughly the same performance regardless of the number of readers and writers.
*	你可以看到一个synchronize ArrayList有大致相同的性能，不管读者和写者有多少。

###	Optimistic locking
*	You do not actually use a mutex when you are performing a calculation, but after the calculation is finished and you’re ready to update the **Atomic** object, you use a method called **compareAndSet( )**.
*	当你执行计算时，你不会真的用一个互斥，但在计算完成并且你准备好了更新Atomic对象时，你用一个叫做compareAndSet()方法。
*	You hand it the old value and the new value, and if the old value doesn’t agree with the value it finds in the **Atomic** object, the operation fails. 
*	你传给它旧的值和新的值，如果旧的值不会同意它在Atomic对象中发现的值，操作就会失败。
*	Using an **Atomic** instead of **synchronized** or **Lock**, you might gain performance benefits.
*	用一个Atomic而不是synchronize或Lock,你可能会增加性能。
*	If **compareAndSet( )** fails, you must decide what to do; this is very important because if you can’t do something to recover, then you cannot use this technique and must use conventional mutexes instead.
*	如果compareAndSet()失败，你必须决定要做啥，这非常重要因为如果你不能恢复的话，你就不能用该技术并且必须用传统互斥取代。
	
###	ReadWriteLocks
*	 The **ReadWriteLock** allows you to have many readers at one time as long as no one is attempting to write.
*	 ReadWriteLock允许你在同一时间有多个读者，只要没有一个想要写入。
*	 The only way to know whether a **ReadWriteLock** will benefit your program is to try it out.
*	 唯一知道一个ReadWriteLock是否会对你的代码有益的方法是去尝试它。
   
##	Active objects
*	 Each object maintains its own worker thread and message queue, and all requests to that object are enqueued, to be run one at a time.
*	 每个对象维护它自己的工作线程和消息队列，并且所有对该对象的请求都入队，一次只运行一个。
*	 So with active objects, we serialize messages rather than methods, which means we no longer need to guard against
problems that happen when a task is interrupted midway through its loop.
*	因此对活动对象，我们序列化消息而非方法，这意味着我们不再需要保护一个任务在其循环中间被中断的问题。
*	Synchronization still happens, but it happens on the message level, by enqueuing the method calls so that only one can happen at a time. 
*	同步依然会发生，但它发生在消息层面，通过入队方法调用来使得一次只有一个可以发生。